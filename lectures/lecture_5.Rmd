---
title: "MT611 - Quantitative Research Methods"
subtitle: "Lecture 5: Categories in the General Linear Model"
author: "Damien Dupré"
date: "Dublin City University"
output:
  xaringan::moon_reader:
    css: ["default", "metropolis", "metropolis-fonts", "css/custom_design.css"]
    lib_dir: libs
    nature:
      beforeInit: "libs/cols_macro.js"
      highlightStyle: zenburn
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include = FALSE}
# libraries --------------------------------------------------------------------
library(anicon)
library(broom)
library(countdown)
library(fontawesome)
library(knitr)
library(kableExtra)
library(papaja)
library(tidyverse)

# general options --------------------------------------------------------------
options(scipen = 999)
set.seed(123)
# chunk options ----------------------------------------------------------------
opts_chunk$set(
  cache.extra = rand_seed, 
  message = FALSE, 
  warning = FALSE, 
  error = FALSE, 
  echo = FALSE,
  cache = FALSE,
  comment = "", 
  fig.align = "center", 
  fig.retina = 3
  )

# data -------------------------------------------------------------------------
organisation_beta <- readr::read_csv(here::here("data/organisation_beta.csv"))  

  # tibble::tibble(
  #   gender = sample(c("male", "female"), 20, replace = TRUE),
  #   location = sample(c("Ireland", "France", "Australia"), 20, replace = TRUE),
  #   perf = rnorm(20, mean = 4, sd = 2),
  #   salary = rnorm(20, mean = 30000, sd = 1000),
  #   js_score = -55 + 0.002 * salary + rnorm(20, mean = 2, sd = 1)
  # ) |>
  # tibble::rownames_to_column("employee") |>
  # dplyr::mutate(
  #   js_score = case_when(
  #     js_score > 10 ~ 10,
  #     js_score < 0 ~ 0,
  #     TRUE ~ js_score
  #   ),
  #   perf = case_when(
  #     perf > 10 ~ 10,
  #     perf < 0 ~ 0,
  #     TRUE ~ perf
  #   ),
  #   salary_c = case_when(
  #     salary >= mean(salary) ~ "high",
  #     salary < mean(salary) ~ "low"
  #   ),
  #   perf_c = case_when(
  #     perf >= mean(perf) + sd(perf) ~ "high",
  #     perf < mean(perf) + sd(perf) & perf >= mean(perf) - sd(perf) ~ "medium",
  #     perf < mean(perf) - sd(perf) ~ "low"
  #   ),
  # ) |>
  # readr::write_csv(here::here("data/organisation_beta.csv"))
  
# analyses ---------------------------------------------------------------------
m_js_high <- mean(organisation_beta$js_score[organisation_beta$salary_c == "high"])
m_js_low <- mean(organisation_beta$js_score[organisation_beta$salary_c == "low"])
lm_c <- lm(js_score ~ salary_c, data = organisation_beta) |> apa_print()
lm_c2 <- lm(js_score ~ salary_c, data = mutate(organisation_beta, salary_c = if_else(salary_c == "low", 1, 2))
) |> apa_print()
lm_c3 <- lm(js_score ~ location, data = organisation_beta) |> aov() |> apa_print()

```

# Vocabulary

"Linear Model", "Linear Regression", "Multiple Regression" or simply "Regression" are all referring to the same model: **The General Linear Model**.

It contains:

- Only one Outcome/Dependent Variable
- One or more Predictor/Independent Variables of any type (categorical or continuous)
- Made of Main and/or Interaction Effects

$$Y = b_{0} + b_{1}\,Predictor\,1 + b_{2}\,Predictor\,2+ ... + b_{n}\,Predictor\,n + e$$

A Linear Regression is used **to test all the hypotheses at once** and to calculate the predictors' estimate.

Specific tests are available for certain type of hypothesis such as T-test or ANOVA but as they are special cases of Linear Regressions, their importance is limited (see [Jonas Kristoffer Lindeløv's blog post: Common statistical tests are linear models](https://lindeloev.github.io/tests-as-linear/)).

---

# General Linear Model Everywhere

.pull-left[
Most of the common statistical models (t-test, correlation, ANOVA; chi-square, etc.) are **special cases of linear models**.

This beautiful simplicity means that there is less to learn. In particular, it all comes down to $y = ax + b$ which most students know from secondary school. 

Unfortunately, **stats intro courses are usually taught as if each test is an independent tool**, needlessly making life more complicated for students and teachers alike.

Here, only **one test is taught to rule them all**: the General Linear Model (GLM).
]

.pull-right[
```{r out.width = "100%"}
include_graphics("https://psyteachr.github.io/msc-data-skills/images/memes/glm_meme.png")
```
]

---

# Analysis of the Estimate

Once the best line is found, each estimate of the tested equation is calculated by a software (i.e., $b_0, b_1, ..., b_n$).

- $b_0$ is the intercept and has no interest for hypothesis testing
- $b_1, ..., b_n$ are predictors' effect estimate and each of them is used to test an hypothesis

The predictors' effect estimate $b_1, ..., b_n$ are **the value of the slope of the best line between each predictor** and the outcome. 

It indicates **how many units of the outcome variable increases/decreases/changes when the predictor increases by 1 unit**

Technically, $b$ is a weight or multiplier applied to the Predictor's values to obtain the Outcome's expected values

---

# Analysis of the Estimate

- If $b_1, ..., b_n = 0$, then:
  - The regression line is horizontal (no slope)
  - When the Predictor increases by 1 unit, the Outcome variable does not change
  - **The null alternative hypothesis is not rejected**

--

- If $b_1, ..., b_n > 0$, then:
  - The regression line is positive (slope up)
  - When the Predictor increases by 1 unit, the Outcome variable increases by $b$
  - **The null alternative hypothesis is rejected and the alternative hypothesis considered as plausible**

--

- If $b_1, ..., b_n < 0$, then:
  - The regression line is negative (slope down)
  - When the Predictor increases by 1 unit, the Outcome variable decreases by $b$
  - **The null alternative hypothesis is rejected and the alternative hypothesis considered as plausible**

---

# Significance of Effect's Estimate

The statistical significance of an effect estimate depends on the **strength of the relationship** and on the **sample size**:

- An estimate of $b_1 = 0.02$ can be very small but still significantly different from $b_1 = 0$
- Whereas an estimate of $b_1 = 0.35$ can be stronger but in fact not significantly different from $b_1 = 0$

--

The significance is the probability to obtain your results with your sample in the null hypothesis scenario:

- Also called $p$-value
- Is between 0% and 100% which corresponds to a value between 0.0 and 1.0

**If the $p$-value is lower to 5% or 0.05, then the probability to obtain your results in the null hypothesis scenario is low enough to say that the null hypothesis scenario is rejected and there must be a link between the variables.**

--

Remember that the $p$-value is the probability of the data given the null hypothesis: $P(data|H_0)$.


---

class: inverse, mline, center, middle

# 1. Hypotheses with Categorical Predictors having 2 Categories

---

# Hypotheses with Categorical Predictors

We will have a deep dive in the processing of Categorical predictor variables with linear regressions:

- How to analyse a Categorical predictor with only 2 categories?
- How to analyse a Categorical predictor with more than 2 categories?

```{r out.width = "50%"}
include_graphics("https://media.makeameme.org/created/what-if-i-8de3498d3a.jpg")
```

---

# Example of Categorical Coding

.pull-left[
Imagine we sample male and female employees to see if the difference between their job satisfaction averages is due **to sampling luck or is reflecting a real difference in the population**.

That is, **is the difference between male and female employees statistically significant?**
]

.pull-right[
```{r}
organisation_beta |> 
  dplyr::select(employee, gender, js_score) |> 
  kable(format = "html")
```
]

---

# Example of Categorical Coding

.pull-left[

.center[Using a Categorical variable having 2 category, **e.g., comparing female vs. male** ...]

```{r fig.height=5}
organisation_beta |> 
  ggplot(aes(x = gender, y = js_score)) +
  geom_point(color = "black", size = 5) +
  stat_summary(fun = "mean", colour = "blue", size = 6, geom = "point") +
  theme_bw() +
  theme(
    text = element_text(size = 20)
  )
```
]

.pull-right[

.center[... is the same as **comparing female coded 1 and male coded 2**]

```{r fig.height=5}
organisation_beta |> 
  mutate(gender_c = case_when(
    gender == "female" ~ 1,
    gender == "male" ~ 2
  )) |> 
  ggplot(aes(x = gender_c, y = js_score)) +
  geom_point(color = "black", size = 5) +
  stat_summary(fun = "mean", colour = "blue", size = 6, geom = "point") +
  scale_x_continuous(breaks = c(1, 2), limits = c(0.5, 2.5)) +
  theme_bw() +
  theme(
    text = element_text(size = 20)
  )
```
]

By default, Categorical variables **are coded using the alphabetical order** (e.g., here Female first then Male) using 1, 2, 3 and so on.

However, you can recode the variable yourself with your own order by creating a new variable using IF statement (e.g., `IF(gender == "female", 2, 1)` in Jamovi)

---

# Categorical Coding in Linear Regression

.pull-left[

.center[Default: **Female = 1** and **Male = 2**]

```{r fig.height=4}
organisation_beta <- organisation_beta |> 
  mutate(gender_c = case_when(
    gender == "female" ~ 1,
    gender == "male" ~ 2
  ))

organisation_beta |> 
  ggplot(aes(x = gender_c, y = js_score)) +
  geom_point(color = "black", size = 5) +
  stat_summary(fun = "mean", colour = "blue", size = 6, geom = "point") +
  scale_x_continuous(breaks = c(1, 2), limits = c(0.5, 2.5)) +
  theme_bw() +
  theme(
    text = element_text(size = 20)
  )
```

```{r results='asis'}
lm(formula = js_score ~ gender_c, data = organisation_beta) |> 
  tidy() |> 
  mutate(p.value = format.pval(round(p.value, 3), eps = 0.001)) |> 
  kable(digits = 2) |>
  kable_styling(font_size = 16)
```
]

.pull-right[

.center[Manual: **Male = 1** and **Female = 2**]

```{r fig.height=4}
organisation_beta <- organisation_beta |> 
  mutate(gender_c = case_when(
    gender == "female" ~ 2,
    gender == "male" ~ 1
  )) 

organisation_beta |> 
  ggplot(aes(x = gender_c, y = js_score)) +
  geom_point(color = "black", size = 5) +
  stat_summary(fun = "mean", colour = "blue", size = 6, geom = "point") +
  scale_x_continuous(breaks = c(1, 2), limits = c(0.5, 2.5)) +
  theme_bw() +
  theme(
    text = element_text(size = 20)
  )
```

```{r results='asis'}
lm(data = organisation_beta, formula = js_score ~ gender_c) |> 
  tidy() |> 
  mutate(p.value = format.pval(round(p.value, 3), eps = 0.001)) |> 
  kable(digits = 2) |>
  kable_styling(font_size = 16)
```
]

---

# Categorical Predictor with 2 Categories

Let's use another example with the `organisation_beta.csv` file

### Variable transformation

Instead of using $salary$ as a **continuous variable**, let's convert it as $salary\_c$ which is a **categorical variable**:
- Everything higher than or equal to salary average is labelled "**high**" salary
- Everything lower than salary average is labelled "**low**" salary

### Hypothesis

The $js\_score$ of employees having a **high** $salary\_c$ is different than the $js\_score$ of employees having a **low** $salary\_c$

### In mathematical terms

$$H_a: \mu(js\_score)_{high\,salary} \neq \mu(js\_score)_{low\,salary}$$
$$H_0: \mu(js\_score)_{high\,salary} = \mu(js\_score)_{low\,salary}$$

---

# Categorical Predictor with 2 Categories

An hypothesis of differences between two groups is easily tested with a Linear Regression:

- If $\mu_{1} \neq \mu_{2}$, the slope of the line between these averages is not null (i.e., $b_{1} \neq 0$)
- If $\mu_{1} = \mu_{2}$, the slope of the line between these averages is null (i.e., $b_{1} = 0$ )

### Explanation

.pull-left[
**Comparing the difference between two averages is the same as comparing the slope of the line crossing these two averages**
- If two averages are **not equal**, then **the slope of the line crossing these two averages is not 0**
- If two averages are **equal**, then the **slope of the line crossing these two averages is 0**
]

.pull-right[
```{r fig.width=4, fig.height=4}
organisation_beta |> 
  ggplot(aes(x = salary_c, y = js_score)) + 
  geom_jitter(width = 0.1) +
  geom_segment(x = 1, xend = 2, y = m_js_high, yend = m_js_low, lwd = 2, color = "red") +
  geom_hline(yintercept = (m_js_high + m_js_low)/2, linetype = "dashed") +
  stat_summary(fun = mean, geom = "errorbar", aes(ymax = ..y.., ymin = ..y..), lwd = 2, color = "blue") +
  theme(
    legend.position = "none",
    text = element_text(size = 20)
  ) +
  labs(caption = "high coded 1 and low coded 2 (default)")
```
]

---

# Categorical Predictor with 2 Categories

### `r faa("exclamation-triangle", animate="flash", speed="slow", color="red")` Warning

JAMOVI and other software **automatically code categorical variable following alphabetical order** but sometimes you need to change these codes.

.pull-left[
For example, here **low coded with the value 1** and **high coded with the value 2** would make more sense.

The way how categorical variables are coded will influence the sign of the estimate (positive vs. negative)

But **it doesn't change the value of the statistical test** nor the $p$-value obtained
]

.pull-right[
```{r fig.width=4, fig.height=4}
organisation_beta |> 
  mutate(salary_c = factor(salary_c, levels = c("low", "high"))) |> 
  ggplot(aes(x = salary_c, y = js_score)) + 
  geom_jitter(width = 0.1) +
  geom_segment(x = 1, xend = 2, yend = m_js_high, y = m_js_low, lwd = 2, color = "red") +
  geom_hline(yintercept = (m_js_high + m_js_low)/2, linetype = "dashed") +
  stat_summary(fun = mean, geom = "errorbar", aes(ymax = ..y.., ymin = ..y..), lwd = 2, color = "blue") +
  theme(
    legend.position = "none",
    text = element_text(size = 20)
    )
```
]

---

# Categorical Predictor with 2 Categories

### To sum up

**To test the influence of a categorical predictor** variable either nominal or ordinal **having two categories** (e.g., high vs. low, male vs. female, France vs. Ireland), it is possible to **test if the $b$ associated to this predictor is significantly higher, lower, or different from 0**.

### Equation

$$js\_score = b_{0} + b_{1}\,salary\_c + e$$

### Communicating results

Exactly the same template as for Continuous Predictors:

> The predictions provided by the alternative model are significantly better than those provided by null model ( `r lm_c2$full_result$modelfit$r2`).

> The effect of $salary\_c$ on $js\_score$ is statistically significant, therefore $H_0$ can be rejected ( `r lm_c2$full_result$salary_c`).

---
class: title-slide, middle

## Testing Main Effects with Categorical Predictors

---

# Testing Categorical Predictors

### In JAMOVI

1. Open your file
2. Set variables in their **correct type** (continuous, cat. nominal or cat. ordinal)
3. **Analyses > Regression > Linear Regression**
4. Set $js\_score$ as DV (i.e., Outcome) and $salary\_c$ as Factors (i.e., Categorical Predictor)

```{r out.width = "100%"}
include_img("jamovi_lm_main_c2.png")
```

---

# Testing Categorical Predictors

### Model

> The prediction provided by the model with all predictors is significantly better than a model without predictors (** `r lm_c$full_result$modelfit$r2`**).

### Hypothesis with Default Coding (high = 1 vs. low = 2)

> The effect of $salary\_c$ on $js\_score$ is statistically significant, therefore $H_{0}$ can be rejected (** `r lm_c$full_result$salary_c`**).

### Hypothesis with Manual Coding (low = 1 vs. high = 2)

> The effect of $salary\_c$ on $js\_score$ is statistically significant, therefore $H_{0}$ can be rejected (** `r lm_c2$full_result$salary_c`**).

---

# Coding of Categorical Predictors

Choosing 1 and 2 are **just arbitrary numerical values** but any other possibility will produce the same $p$-value

However, choosing codes separated by 1 is handy because it's easily interpretable, the **estimate corresponds to the change from one category to another**:

> The $js\_score$ of "high" $salary\_c$ employees is `r round(m_js_high - m_js_low, 2)` higher than the $js\_score$ of "low" $salary\_c$ employees (when "low" is coded 1 and "high" coded 2).

---

# Coding of Categorical Predictors

### Special case called **Dummy Coding** when a category is coded 0 and the other 1:
- Then the intercept, value of $js\_score$ when salary is 0 corresponds to the category coded 0
- The test of the intercept is the test of the average for the category coded 0 against an average of 0
- Is called simple effect

### Special case called **Deviation Coding** when a category is coded 1 and the other -1:
- Then the intercept, corresponds to the average between the two categories
- The test of the intercept is the test of the average for the variable
- However, the distance between 1 and -1 is 2 units so the estimate is not as easy to interpret, therefore it is possible to choose categories coded 0.5 vs. -0.5 instead

---

# Dummy Coding in Linear Regression

Dummy Coding is when a category is coded 0 and the other coded 1. 

For example, in JAMOVI recode female as 0 and male as 1 (Dummy Coding):

```
IF(gender == "female", 0, 1)
```

Dummy Coding is useful because one of the category becomes the intercept and is tested against 0.

.pull-left[

```{r fig.height=4}
organisation_beta <- organisation_beta |> 
  mutate(gender_c = case_when(
    gender == "female" ~ 0,
    gender == "male" ~ 1
  ))

organisation_beta |> 
  ggplot(aes(x = gender_c, y = js_score)) +
  geom_point(color = "black", size = 5) +
  stat_summary(fun = "mean", colour = "blue", size = 6, geom = "point") +
  scale_x_continuous(breaks = c(0, 1), limits = c(-0.5, 1.5)) +
  theme_bw() +
  theme(
    text = element_text(size = 20)
  )
```
]

.pull-right[

```{r results='asis'}
lm(data = organisation_beta, formula = js_score ~ gender_c) |> 
  broom::tidy() |> 
  dplyr::mutate(p.value = format.pval(round(p.value, 3), eps = 0.001)) |> 
  kable(digits = 2) |>
  kable_styling(font_size = 16)
```
]

---

# Deviation Coding in Linear Regression

Deviation Coding is when the intercept is situated between the codes of the categories. 

For example, in JAMOVI recode female as -1 and male as 1 (Deviation Coding):

```
IF(gender == "female", -1, 1)
```

Deviation Coding is useful because **the average of the categories becomes the intercept** and is tested against 0.

However, in the Deviation Coding **using -1 vs. +1, the distance between the categories is 2** not 1. Therefore, even if the test of the slop is the exact same, the value of the slop (the estimate) is twice lower.

Consequently it is possible to use **a Deviation Coding with -0.5 vs. +0.5 to keep the distance of 1** between the categories.

For example, in JAMOVI recode female as -0.5 and male as 0.5 (Deviation Coding):

```
IF(gender == "female", -0.5, 0.5)
```

---

# Deviation Coding in Linear Regression

.pull-left[

.center[Female = -1 and Male = 1]

```{r fig.height=4}
organisation_beta <- organisation_beta |> 
  mutate(gender_c = case_when(
    gender == "female" ~ -1,
    gender == "male" ~ 1
  ))

organisation_beta |> 
  ggplot(aes(x = gender_c, y = js_score)) +
  geom_point(color = "black", size = 5) +
  stat_summary(fun = "mean", colour = "blue", size = 6, geom = "point") +
  scale_x_continuous(breaks = c(-1, 1), limits = c(-1.5, 1.5)) +
  theme_bw() +
  theme(
    text = element_text(size = 20)
  )
```

```{r results='asis'}
lm(data = organisation_beta, formula = js_score ~ gender_c) |> 
  broom::tidy() |> 
  dplyr::mutate(p.value = format.pval(round(p.value, 3), eps = 0.001)) |> 
  kable(digits = 2) |>
  kable_styling(font_size = 16)
```
]

.pull-right[

.center[Female = -0.5 and Male = 0.5]

```{r fig.height=4}
organisation_beta <- organisation_beta |> 
  mutate(gender_c = case_when(
    gender == "female" ~ -0.5,
    gender == "male" ~ 0.5
  ))

organisation_beta |> 
  ggplot(aes(x = gender_c, y = js_score)) +
  geom_point(color = "black", size = 5) +
  stat_summary(fun = "mean", colour = "blue", size = 6, geom = "point") +
  scale_x_continuous(breaks = c(-0.5, 0.5), limits = c(-1, 1)) +
  theme_bw() +
  theme(
    text = element_text(size = 20)
  )
```

```{r results='asis'}
lm(data = organisation_beta, formula = js_score ~ gender_c) |> 
  broom::tidy() |> 
  dplyr::mutate(p.value = format.pval(round(p.value, 3), eps = 0.001)) |> 
  kable(digits = 2) |>
  kable_styling(font_size = 16)
```
]

---
class: title-slide, middle

## Testing Interaction Effects with Categorical Predictors

---

# Interaction with Categorical Predictors

### In JAMOVI

1. Open your file
2. Set variables according their type
3. **Analyses > Regression > Linear Regression**
4. Set $js\_score$ as DV and $salary\_c$ as well as $gender$ as Factors
4. In the **Model Builder** option: 
  - Select both $salary\_c$ and $gender$ to bring them in the Factors at once

### Model Tested

$$js\_score = b_{0} + b_{1}\,salary\_c + b_{2}\,gender + b_{3}\,salary\_c*gender + e$$

Note: The test of the interaction effect corresponds to the test of a variable resulting from the multiplication between the codes of $salary\_c$ and the codes of $gender$.

---

# Interaction with Categorical Predictors

```{r out.width = "100%"}
include_img("jamovi_lm_main_cint.png")
```

---
class: title-slide, middle

## Live Demo

---
class: title-slide, middle

## Exercise

With the `organisation_beta.csv` data, test the following models and conclude on each effect:

Model 1: $js\_score = b_{0} + b_{1}\,perf + b_{2}\,gender + b_{3}\,perf*gender + e$

Model 2: $js\_score = b_{0} + b_{1}\,perf + b_{2}\,location + b_{3}\,perf*location+ e$

```{r}
countdown(minutes = 10, warn_when = 60)
```

---

class: inverse, mline, center, middle

# 2. Hypotheses with Categorical Predictor having 3+ Categories

---

# Categorical Predictor with 3+ Categories

### Problem with more than 2 groups

I would like to test the effect of the variable $location$ which has 3 categories: "Ireland", "France" and "Australia".

```{r}
include_img("jamovi_lm_main_c31.png")
```

In the Model Coefficient Table, to test the estimate of $location$, there is not 1 result for $location$ but 2!
- Comparison of "Australia" vs. "France"
- Comparison of "Australia" vs. "Ireland"

**Why multiple $p$-value are provided for the same predictor?**

---

# Coding Predictors with 3+ categories

### Variables
- Outcome = $js\_score$ (from 0 to 10)
- Predictor = $location$ (3 categories: *Australia*, *France* and *Ireland*)

.pull-left[
```{r}
organisation_beta |> 
  select(employee, location, js_score) |> 
  kable(format = "html") |> 
  kable_styling(font_size = 14)
```
]

.pull-right[
```{r fig.height=5}
organisation_beta |> 
  ggplot(aes(location, js_score)) +
  geom_point(color = "black", size = 5) +
  stat_summary(fun = "mean", colour = "blue", size = 6, geom = "point") +
  scale_x_discrete("location") +
  theme_bw() +
  theme(
    text = element_text(size = 20)
  )
```
]

---

# Coding Predictors with 3+ categories

$t$-test can only compare 2 categories. Because Linear Regression Models are (kind of) $t$-test, categories will be compared 2-by-2 with one category as the reference to compare all the others.

For example a linear regression of $location$ on $js\_score$ will display not one effect for the $location$ but the effect of the 2-by-2 comparison using a reference group by alphabetical order:

```{r results='asis'}
lm(data = organisation_beta, formula = js_score ~ location) |> 
  tidy() |> 
  mutate(p.value = format.pval(round(p.value, 3), eps = 0.001)) |> 
  kable(digits = 2) |>
  kable_styling(font_size = 16)
```

In our case the reference is the group "Australia" (first letter).

Here is our problem: **How to test the overall effect of a variable with 3 or more Categories?**

---

# ANOVA Test for Overall Effects

BesideLinear Regression and $t$-test, researchers are using ANOVA a lot. ANOVA, stands for Analysis of Variance and is also a sub category of Linear Regression Models.

ANOVA is used to calculate the overall effect of categorical variable having more that 2 categories as $t$-test cannot cope. In the case of testing 1 categorical variable, a "one-way" ANOVA is performed.

**How ANOVA is working?**

### In real words
- $H_a$: at least one group is different from the others
- $H_0$: all the groups are the same

### In mathematical terms
- $H_a$: it is **not true** that $\mu_{1} = \mu_{2} = \mu_{3}$
- $H_0$: it is **true** that $\mu_{1} = \mu_{2} = \mu_{3}$

---

# ANOVA Test for Overall Effects

I won't go too much in the details but to check if at least one group is different from the others, the distance of each value to the overall mean (Between−group variation) is compared to the distance of each value to their group mean (Within−group variation).

**If the Between−group variation is the same as the Within−group variation, all the groups are the same.**

```{r out.width = '100%'}
include_img("one_way_anova_basics.png")
```

---

# ANOVA in our Example

An hypothesis for a categorical predictor with 3 or more categories predicts that **at least one group among the 3 groups will have an average significantly different than the other averages**.

### Hypothesis Formulation

> The $js\_score$ of employees working in at least one specific $location$ will be significantly different than the $js\_score$ of employees working in the other $location$.

### In mathematical terms

- $H_0$: it is true that $\mu(js\_score)_{Ireland} = \mu(js\_score)_{France} = \mu(js\_score)_{Australia}$
- $H_a$: it is **not** true that $\mu(js\_score)_{Ireland} = \mu(js\_score)_{France} = \mu(js\_score)_{Australia}$

This analysis is usually preformed using a one-way ANOVA but as ANOVA are special cases of the General Linear Model, let's keep this approach.

---

# ANOVA in our Example

```{r}
organisation_beta |> 
  ggplot(aes(x = location, y =  js_score)) + 
  geom_jitter(width = 0.1) +
  geom_hline(yintercept = mean(organisation_beta$js_score), linetype = "dashed") +
  stat_summary(fun = mean, geom = "errorbar", aes(ymax = ..y.., ymin = ..y..), lwd = 2, color = "blue") +
  theme(
    legend.position = "none",
    text = element_text(size = 20)
  )
```

---

# ANOVA in our Example

### In JAMOVI

1. Open your file
2. Set variables according their type
3. Analyses > Regression > Linear Regression
4. Set $js\_score$ as DV and $location$ as Factors
5. In the **Model Coefficients** option: 
  - Select **Omnibus Test ANOVA test**

```{r out.width = "40%"}
include_img("jamovi_lm_main_c32.png")
```

### Results

> There is no significant effect of employee's $location$ on their average $js\_score$ ( `r lm_c3$statistic$location`)

---
class: title-slide, middle

## Live Demo

---
class: title-slide, middle

## Exercise

Using the `organisation_beta.csv` file, test the following models and conclude on the hypothesis related to each estimate:

Model 1: $js\_score = b_{0} + b_{1}\,salary + b_{2}\,location + b_{3}\,perf + e$

Model 2: $$js\_score = b_{0} + b_{1}\,salary + b_{2}\,location + b_{3}\,perf + b_{4}\,salary*location +$$
$$b_{5}\,perf*location + b_{6}\,perf*salary + b_{7}\,salary*location*perf + e$$

```{r}
countdown(minutes = 5, warn_when = 60)
```

---
class: inverse, mline, left, middle

# 3. Manipulating Contrast with Categorical Predictors

---

# Post-hoc Tests 

Imagine you want to test the specific difference between France and Ireland, **how to obtain a test of specific categories when using a categorical variable with 3 or more categories?**

The "Post-hoc" runs a separate $t$-test for all the pairwise category comparison:

```{r}
res <- jmv::ANOVA(
    formula = js_score ~ location,
    data = organisation_beta,
    postHoc = ~ location)

res$postHoc[[1]] |> 
  kable(digits = 2)
```

Even if it looks useful, "Post-hoc" test can be considered as $p$-Hacking because **there is no specific hypothesis testing, everything is compared**.

Some corrections for multiple tests are available such as Tukey, Scheffe, Bonferroni or Holm, but they are still very close to the bad science boundary.

---

# Contrasts or Factorial ANOVA

By using specific codes for the categories (also called **contrasts**), it is possible to test more precise hypotheses.

Actually, you are mastering Contrasts already. When a recoding is done on a variable with 2 categories (like Dummy Coding or Deviation Coding), a contrast is applied. 

When a recoding is used on more than 2 categories, three rules have to be applied:

--

- Rule 1: **Categories with the same code are tested together**

> Coding Ireland 1, France 1 and Australia 2 compares Ireland and France versus Australia

--

- Rule 2: **The number of contrast possible is the number of categories - 1**

> $location$ has 3 categories so 2 contrast comparisons can be performed

--

- Rule 3: **The value 0 means the category is not taken into account**

> Coding Ireland 1, France 0 and Australia 2 compares Ireland versus Australia

--

To understand contrasts, the best is to manually creating them in your spreadsheet.

---

# Sum to Zero Contrasts

Also called "Simple" contrast, each contrast encodes the difference between one of the groups and a baseline category, which in this case corresponds to the first group:

.pull-left[
```{r}
contrast_df <- 
  tribble(
    ~`Predictor's categories`, ~Contrast1, ~Contrast2,
    "Placebo",                 -1,         -1,
    "Vaccine 1",                1,          0,
    "Vaccine 2",                0,          1
  )

contrast_df |> 
  kable()
```
]

.pull-right[
```{r fig.height=4}
contrast_df |> 
  mutate(Outcome = c(4, 5, 9)) |> 
  ggplot(aes(`Predictor's categories`, Outcome)) +
  geom_col() +
  theme_bw() +
  theme(text = element_text(size = 20))
```
]

In this example:
- Contrast 1 compares Placebo with Vaccine 1
- Contrast 2 compares Placebo with Vaccine 2

However I won't be able to compare Vaccine 1 and Vaccine 2

---

# Polynomial Contrasts

They are the most powerful of all the contrasts to test linear and non linear effects: Contrast 1 is called Linear, Contrast 2 is Quadratic, Contrast 3 is Cubic, Contrast 4 is Quartic ...

.pull-left[
```{r}
contrast_df <- 
  tribble(
    ~`Predictor's categories`, ~Contrast_1, ~Contrast_2,
    "Low",                     -1,           1,
    "Medium",                   0,          -2,
    "High",                     1,           1
  )

contrast_df |> 
  kable()
```
]

.pull-right[
```{r fig.height=4}
contrast_df |> 
  mutate(
    Outcome = c(4, 5, 9),
    `Predictor's categories` = factor(`Predictor's categories`, levels = c("Low", "Medium", "High"))
  ) |> 
  ggplot(aes(`Predictor's categories`, Outcome)) +
  geom_col() +
  theme_bw() +
  theme(text = element_text(size = 20))
```
]

In this example:
- Contrast 1 checks the linear increase between **Low**, **Medium**, **High**
- Contrast 2 checks the quadratic change between **Low**, **Medium**, **High** 

If the hypothesis specified a linear increase, we would expect Contrast 1 to be significant but Contrast 2 to be non-significant

---
class: title-slide, middle

## Live Demo

---

# Comparison of Contrasts Results

```{r}
organisation_beta <- organisation_beta |> 
  dplyr::mutate(
    treatment_c1 = case_when(
      location == "Ireland" ~ 1, 
      location == "France" ~ 0, 
      location == "Australia" ~ 0
    ),
    treatment_c2 = case_when(
      location == "Ireland" ~ 0, 
      location == "France" ~ 0, 
      location == "Australia" ~ 1
    ),
    sum_c1 = case_when(
      location == "Ireland" ~ 1, 
      location == "France" ~ -1, 
      location == "Australia" ~ 0
    ),
    sum_c2 = case_when(
      location == "Ireland" ~ 0, 
      location == "France" ~ -1, 
      location == "Australia" ~ 1
    ),
    poly_c1 = case_when(
      location == "Ireland" ~ 0, 
      location == "France" ~ -1, 
      location == "Australia" ~ 1
    ),
    poly_c2 = case_when(
      location == "Ireland" ~ -2, 
      location == "France" ~ 1, 
      location == "Australia" ~ 1
    )
  )
```

Let's see what happens with different contrast to compare the average $js\_score$ according employee's $location$: **France**, **Ireland**, **Australia**

### Sum to Zero Contrasts

.pull-left[
```{r}
tribble(
  ~category, ~sum_c1, ~sum_c2,
  "France",  -1,  -1,
  "Ireland",  1,   0,
  "Australia",    0,   1
) |> 
  kable() |>
  kable_styling(font_size = 17)
```
]

.pull-right[
```{r results='asis'}
lm(data = organisation_beta, formula = js_score ~ sum_c1 + sum_c2) |> 
  tidy() |> 
  mutate(p.value = format.pval(round(p.value, 3), eps = 0.001)) |> 
  kable(digits = 2) |>
  kable_styling(font_size = 17)
```
]

### Polynomial Contrasts

.pull-left[
```{r}
tribble(
  ~category, ~poly_c1, ~poly_c2,
  "France",  -1,   1,
  "Ireland",  0,  -2,
  "Australia",    1,   1
) |> 
  kable() |>
  kable_styling(font_size = 17)
```
]

.pull-right[
```{r results='asis'}
lm(data = organisation_beta, formula = js_score ~ poly_c1 + poly_c2) |> 
  tidy() |> 
  mutate(p.value = format.pval(round(p.value, 3), eps = 0.001)) |> 
  kable(digits = 2) |>
  kable_styling(font_size = 17)
```
]

---
class: title-slide, middle

## Exercise

1. Using the `organisation_beta.csv` file, create contrast variables to reproduce the results obtained with Sum to Zero Contrasts

2. When it's done, explicit the hypotheses tested, the representation of the models and their corresponding equation

```{r}
countdown(minutes = 10, warn_when = 60)
```

---

# Solution - Sum to Zero Contrasts

Variables:

- Outcome = $js\_score$ (from 0 to 10)
- Predictor 1 = $sum\_c1$ (Ireland vs France)
- Predictor 2 = $sum\_c2$ (Australia vs France)

Hypotheses:

- $H_{a_1}$: The average $js\_score$ of Irish employees is different than the average $js\_score$ of French employees
  - $H_{0_1}$: The average $js\_score$ of Irish employees is the same as the average $js\_score$ of French employees

- $H_{a_2}$: The average $js\_score$ of Australia employees is different than the average $js\_score$ of France employees
  - $H_{0_2}$: The average $js\_score$ of Australia employees is the same as the average $js\_score$ of France employees

---

# Solution - Sum to Zero Contrasts

Model:

```{r eval=TRUE, fig.align="center"}
DiagrammeR::grViz("
  digraph {
    graph [rankdir = LR]
    node [shape = circle]
    js_score
    node [shape = square]
    sum_c1, sum_c2
    
    sum_c1 -> js_score [label= b1]
    sum_c2 -> js_score [label= b2]
  }", height = 200, width = 500)
```

Equation:

- $js\_score = b_{0} + b_{1}\,sum\_c1 + b_{2}\,sum\_c2 + e$

---
class: inverse, mline, left, middle

<img class="circle" src="https://github.com/damien-dupre.png" width="250px"/>

# Thanks for your attention and don't hesitate to ask if you have any questions!

[`r fa(name = "twitter")` @damien_dupre](http://twitter.com/damien_dupre)  
[`r fa(name = "github")` @damien-dupre](http://github.com/damien-dupre)  
[`r fa(name = "link")` damien-datasci-blog.netlify.app](https://damien-datasci-blog.netlify.app)  
[`r fa(name = "paper-plane")` damien.dupre@dcu.ie](mailto:damien.dupre@dcu.ie)
