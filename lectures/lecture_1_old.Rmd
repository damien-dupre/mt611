---
title: "MT611 - Quantitative Research Methods"
subtitle: "Lecture 1: Variable, model, hypothesis and equation"
author: "Damien DuprÃ©"
date: "Dublin City University"
output:
  xaringan::moon_reader:
    css: ["default", "metropolis", "metropolis-fonts", "css/custom_design.css"]
    lib_dir: libs
    nature:
      beforeInit: "libs/cols_macro.js"
      highlightStyle: zenburn
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include = FALSE}
# general options --------------------------------------------------------------
options(scipen = 999)
set.seed(123)
# chunk options ----------------------------------------------------------------
knitr::opts_chunk$set(
  cache.extra = knitr::rand_seed, 
  message = FALSE, 
  warning = FALSE, 
  error = FALSE, 
  echo = FALSE,
  cache = FALSE,
  comment = "", 
  fig.align = "center", 
  fig.retina = 3
  )
# libraries --------------------------------------------------------------------
library(tidyverse)
library(nomnoml)
library(DiagrammeR)
library(ggrepel)
library(fontawesome)
library(tweetrmd)
library(plotly)
library(gapminder)
library(patchwork)
library(webshot2)
library(VennDiagram)
library(countdown)
```

# Concept Relationships

```{nomnoml, fig.width=12, fig.height=3}
#stroke: black
#direction: right
#align: center
[Variables]->[Hypotheses]
[Hypotheses]->[Model]
[Model]->[Equation]
```

---
class: inverse, mline, center, middle

# 1. Variables

---

# Academic Papers' Introduction

An introduction is a section **presenting your variables and why you investigate them**.

There is little reference to previous academic research, just a description of actual facts.

It should end with your **Research Question**, a question that includes all the main variables investigated which wonders about a potential relationship between them.

For example:
- "What is the relationship between Job Satisfaction, Salary and Gender?"
- "How does sales experience influence the performance of sales managers and sales representatives?"

```{r out.width='25%'}
knitr::include_graphics("https://memegenerator.net/img/instances/65219961/there-will-come-a-day-i-easily-write-an-introduction-to-a-paper-but-it-is-not-this-day.jpg")
```

---

# What is a Variable?

A variable itself is a subtle concept, but basically it comes down to finding some way of assigning *numbers or characters* to **labels**.

For example:

- My **height** is *183 cm*
- This morning, I had a *large* **coffee**
- My **gender** is *male*

The **bold part is "the thing that varies"** and the *italicised part is "the value of the variable"*.

> Let's collect more data about our classmates on these three variables: height, coffee and gender!

--

### Important!

- The variable **variability** corresponds to how numbers or characters according each observation.
- Each variable has a **Role** and a **Type**, it is essential to learn how to identify them.

---

# Latent Variables

A questionnaire/survey is made of multiple questions (also called items)

All items that are related to the measurement of a same theoretical construct are constituting a scale.

#### The theoretical construct measured by the scale is called Latent Variable.

To be analysed a scale has some requirements:

1. All the items must have the same range of possibilities/modalities
2. All the items must correlate together (scale reliability)
3. A unique theoretical construct score has to be calculated from all the items even if it contains subscales.

There are two way to obtain the score of a Latent Variable: 

- Average of all items (reversed if necessary)
- Factor/Component analysis

---

# Latent Variables

Scale to measure the "Perceived Ease-of-use" of MS Excel in 4 items were measured from 1 "totally disagree" to 7 "totally agree":

.pull-left[
- q1. I think learning MS Excel is easy
- q2. Understanding MS Excel is easy
- q3. I am good at using MS Excel
- q4. I think using MS Excel is easy
]

.pull-right[
```{r}
DiagrammeR::grViz("
digraph rmarkdown {
  graph [rankdir = RL]
  
  node [shape = oval]
  'Perceived Ease-of-use
  of MS Excel'
  
  node [shape = box]
  q1; q2; q3; q4
  
  'Perceived Ease-of-use
  of MS Excel'-> {q1 q2 q3 q4}   

}
", height = 200)
```
]

--

Here are the results with 3 students. The score of the "Perceived Ease-of-use of MS Excel" latent variable is calculated using the average of all items.

```{r}
tribble(
  ~employee, ~q1, ~q2, ~q3, ~q4,
  "Sinead",   7,  5,   7,   7,
  "Patrick",   5,  4,   6,   6, 
  "Damien",   3,  1,   2,   3
) %>% 
  rowwise() %>% 
  mutate(peo_score = mean(c(q1, q2, q3, q4))) %>% 
  kable()
```

---

# Validity and Reliability

**Validity = is my variable measuring the construct that I think I am measuring?**
- Does the measurement make sense? 
- Would the results be reproduced with another scale measuring the same latent variable?
- Are the results correlated to latent variables that are related?

Validity test is only performed when a scale is created (no need for existing scales)

**Reliability = consistency of items inside a measurement**
- Test-retest reliability
- Inter-rater reliability
- Correlation inter-item (Cronbach's alpha)

Reliability test is performed every time a scale is used but only using Cronbach's alpha

---

# Validity and Reliability

```{r out.width = "50%"}
knitr::include_graphics("https://www.publichealthnotes.com/wp-content/uploads/2018/08/560px-Reliability_and_validity.svg_.png")
```

---
class: title-slide, middle

## Type of Variables

---

# Type of Variables

Variables can have different types:

- **Categorical**: If the variable's possibilities are words or sentences (character string)

  - if the possibilities cannot be ordered: Categorical Nominal (*e.g.*, $gender$ male, female, other)
  
  - if the possibilities can be ordered: Categorical Ordinal (*e.g.*, $size$ S, M, L)
  
- **Continuous**: If the variable's possibilities are numbers (*e.g.*, $age$, $temperature$, ...) 

> Warning: Variables can be converted to either Categorical and Continuous but it is always better to keep them in their correct scale.

```{r out.width='30%'}
knitr::include_graphics("img/jamovi_icons.png")
```

---
class: title-slide, middle

## Role of Variables

---

# Predictors, Outcomes and Controls

It's important to keep the two roles "variable doing the explaining" and "variable being explained" distinct.

Let's denote the:
 - **Outcome**: "variable to be explained" (also called $Y$, Dependent Variable, or DV)
 - **Predictor**: "variable doing the explaining" (also called $X$, Independent Variable, or IV)
 
--

Statistics is only about identifying relationship between Predictor and Outcome variables also called **effect**

> An effect between 2 variables means that the changes in the values of a predictor variable are related to changes in the values of an outcome variable.

> The aim of an Academic Report is to investigate if the **Variability of the Outcome Variable** is related to the variability of Predictor Variables.

---

# Predictors, Outcomes and Controls

Imagine a the variability of the Outcome Variable is a birthday cake. 

Now, imagine each predictor is a guest having a slice of the cake:

- **Case 1:** There is only one guest eating all the cake.

  - Then the predictor explains all the variability of the outcome variable. 

- **Case 2:** There is only one guest eating a slice which is not the all cake.

  - The predictor explains some of the outcome's variability. A statistical test is required to know if the predictor explains a significant part of the outcome's variability.
  
- **Case 3:** There is more than one guest, they will take their slices of the cake which can be small or big. 

   - Each predictor will explains more or less variability of the outcome. However, the more guest there is, the smaller the slices.

---

# Predictors, Outcomes and Controls

An effect between a predictor variable and an outcome variable corresponds to the following model:

```{nomnoml, fig.width=12, fig.height=3}
#stroke: black
#direction: right
#align: center

[Predictor]->[Outcome]
```

This arrow does not suggest causation but indicate correlation between $Predictor$ and $Outcome$, there is no assumption of one causing the other. **An "effect" is reciprocal and does not involves causality**.

Causality analysis is an other kind of test that involves:
- To be sure that 2 variables are correlated
- That one variable is the antecedent of the other
- That no other variable is explaining this relationship

---

# Predictors, Outcomes and Controls

A significant effect of a $Predictor$ on an $Outcome$ variable means that **a predictor is explaining enough variance of the outcome** variable to show a significant relationship.

.pull-left[

- If there is no effect between the variables, they are not sharing enough of their variability

```{r, fig.height=5}
venn.plot <- draw.pairwise.venn(
  100, 100, 10, c("Predictor", "Outcome"), ind = FALSE, cex = 5, cat.cex	= 2, cat.pos	
= c(0,0))
grid.draw(venn.plot)
```

]

.pull-right[

- If there is an effect between the variables, they are sharing a big part of their variability

```{r, fig.height=5}
venn.plot <- draw.pairwise.venn(
  100, 100, 40, c("Predictor", "Outcome"), ind = FALSE, cex = 5, cat.cex	= 2, cat.pos	
= c(0,0))
grid.draw(venn.plot)
```
]

To decide, if the part of the shared variability is big enough, a statistical test is required.

---

# Predictors, Outcomes and Controls

## Correlation not Causation

Hypothesis testing evaluates how two or more variable are related or correlated, there is no assumption of one causing the other:

* An "effect" is reciprocal and does not involves causality
* Causality analysis is an other kind of test that involves:
  1. To be sure that 2 variables are correlated
  2. That one variable is the antecedent of the other
  3. That no other variable is explaining this relationship

## Control Variables

The only difference for **control variables** is that they are not included in the model and in the hypotheses but they are in the equation.

They are used to remove an irrelevant explanation of the variable changes.

---
class: title-slide, middle

## Exercise

In the research paper you have selected, identify the variables that are used to produce statistical results (e.g. $p-values$).

Indicate their Type and Role by using the following table:

|variable_name|variable_type|variable_role|
|-------------|-------------|-------------|
|var 1        |type         |role         |
|...          |type         |role         |
|var n        |type         |role         |

```{r}
countdown(minutes = 10, warn_when = 60)
```

---
class: inverse, mline, center, middle

# 2. Formulate your Hypotheses from your Literature Review

---

# Model and Hypotheses

Model: Overview of the predicted relationship between variables

Hypotheses:
- Predictions supported by theory/literature
- Tested to confirm or refute
- Can be revised or abandoned

Hypotheses are affirmations designed to precisely describe the predicted relationships between variables. 

*âHypothesis statements contain two or more variables that are measurable or potentially measurable and that specify how the variables are relatedâ* (Kerlinger, 1986)

---

# Alternative *vs.* Null Hypotheses

Every hypothesis has to state a difference (between groups or according values) also called $H_a$ (for alternative hypothesis) or $H_1$

Every alternative hypothesis has a null hypothesis counterpart (no difference between groups or according values) also called $H_0$ (pronounce H naught or H zero)
  
> **Statistics are used to test the probability of obtaining your results if the Null Hypothesis is true. If this probability is low, then we reject the Null Hypothesis (and consider the Alternative Hypothesis as credible).**

**Warning:** An Alternative Hypothesis cannot test equality between groups or modalities, they can only test differences or effects

---

# Hypothesis Testing

A hypothesis test consists of a test between two competing hypotheses:

### .center[An alternative hypothesis $H_a$ versus a null hypothesis $H_0$]

Generally the null hypothesis is a claim that there is âno effectâ or âno difference of interestâ. In many cases, the null hypothesis represents the status quo or a situation that nothing interesting is happening. Furthermore, generally the alternative hypothesis is the claim the experimenter or researcher wants to establish or find evidence to support. It is viewed as a âchallengerâ hypothesis to the null hypothesis $H_0$.

---

# Formulating Hypotheses

Hypotheses include

- Predictor(s) / Independent Variable(s)
- Outcome / Dependent Variable (DV)
- Effect strength and direction
 - different is called two-tailed or two-sided
 - higher/lower is called one-tailed or one-sided

![](https://www.simplypsychology.org/controlled-experiment.jpg)

---

# Effect Strength and Direction

A comparative word in hypotheses:

- Different
- Bigger/Higher/Better *vs.* Smaller/Lower/Worst
- Increase *vs.* Decrease

The letter $\beta$ in equations

Hypothesis cannot test equality between groups or modalities

Hypothesis can only test differences

---

# Statistical Test

I could try to present you the mathematics behind the T-test but the drawing of Allison Horst are much easier to understand.

```{r out.width = '70%'}
knitr::include_graphics("img/allison_horst/EOGPgsIUUAE4b1C.jpg")
```

---

# Statistical Test

```{r out.width = '100%'}
knitr::include_graphics("img/allison_horst/EOGPh_9UcAAOAyQ.jpg")
```

---

# Statistical Test

```{r out.width = '100%'}
knitr::include_graphics("img/allison_horst/EOGPjOYVAAAA7uX.jpg")
```

---

# Statistical Test

```{r out.width = '100%'}
knitr::include_graphics("img/allison_horst/EOGPkiyU0AEy1I5.jpg")
```

---

# Statistical Test

```{r out.width = '100%'}
knitr::include_graphics("img/allison_horst/EOGPlvJU8AIDLEV.jpg")
```

---

# Statistical Test

```{r out.width = '100%'}
knitr::include_graphics("img/allison_horst/EOGPnCXVUAAK5A1.jpg")
```

---

# Statistical Test

```{r out.width = '100%'}
knitr::include_graphics("img/allison_horst/EOGPonNUwAA37lg.jpg")
```

---

# Statistical Test

```{r out.width = '100%'}
knitr::include_graphics("img/allison_horst/EOGPqCzUcAABLwr.jpg")
```

---

# Statistical Test

```{r out.width = '100%'}
knitr::include_graphics("img/allison_horst/EOGPssbVUAIX0wN.jpg")
```

---

# Main Effect Hypothesis

Replace with yours:

- if IV is Categorical and DV is Categorical or Continuous

{**IV Condition1**} is {**>or<**} on {**DV**} than {**IV Condition2**}

- if IV is Continuous and DV is Categorical or Continuous

The {**DV**} {**increase or decrease**} when {**IV**} {**increase or decrease**}

---

# Main Effect Hypothesis Examples

Variables:
- DV = math exam results (continuous from 0 to 100)
- IV = breakfast (categorical *yes* or *no*)

```{r eval=TRUE, fig.align="left"}
DiagrammeR::grViz("
  digraph {
    graph [rankdir = LR]
    
    'breakfast' -> 'math exam results'
  }", height = 200)
```

--

Hypothesis:

- Students who eat breakfast will perform better on a math exam than students who do not eat breakfast

---

# Main Effect Hypothesis Examples

Variables:
- DV = driving errors (continuous from 0 to Inf.)
- IV = motorists talking on the phone (categorical *yes* or *no*)

```{r eval=TRUE, fig.align="left"}
DiagrammeR::grViz("
  digraph {
    graph [rankdir = LR]
    
    'motorists talking on the phone' -> 'driving errors'
  }", height = 200)
```

--

Hypothesis:

- Motorists who talk on the phone while driving will be more likely to make errors on a driving course than those who do not talk on the phone

---

# Main Effect Hypothesis Examples

Variables:

- DV = math exam results (continuous from 0 to 100)
- IV = studentsâ sleep time (continuous from 0h to 24h)

```{r eval=TRUE, fig.align="left"}
DiagrammeR::grViz("
  digraph {
    graph [rankdir = LR]
    
    'studentsâ sleep time' -> 'math exam results'
  }", height = 200)
```

--

Hypothesis:

- The results on a math exam increase when studentsâ sleep time increase

---

# Interaction Effect Hypothesis

Replace with yours:

- if IV1 is Categorical, IV2 is Categorical or Continuous and DV is Categorical or Continuous

The effect of {**IV2**} on {**DV**} is {**>or<**} for {**IV1 Condition1**} than for {**IV1 Condition2**}

- if IV1 is Continuous, IV2 is Categorical or Continuous and DV is Categorical or Continuous

The effect of {**IV2**} on {**DV**} is {**>or<**} when {**IV1**} {**increase or decrease**}

---

# Interaction Effect Hypothesis

In simple words ...

```{r out.width="50%"}
tweetrmd::tweet_screenshot(
  tweetrmd::tweet_url("GioraSimchoni", "1255499208670527490"),
  maxwidth = 300,
  hide_media = FALSE,
  theme = "dark"
  )
```

---

# Interaction Effect Hypothesis Examples

Variables:

- DV = math exam results (continuous from 0 to 100)
- IV1 = gender (categorical male vs. female)
- IV2 = sleep deprivation (categorical low, medium, high)

```{r eval=TRUE, fig.align="left"}
DiagrammeR::grViz("
  digraph {
    graph [rankdir = LR]
  
    node []
    'sleep deprivation'; 'math exam results'; gender
    node [shape = point, width = 0, height = 0]
    ''
    
    gender -> ''
    'sleep deprivation' -> '' [arrowhead = none]
    ''-> 'math exam results'
    
    subgraph {
      rank = same; gender; '';
    }
  }", height = 200)
```

--

Hypothesis:

- The effect of sleep deprivation on Math scores is higher for Males than for Females

---

# Interaction Effect Hypothesis Examples

Variables:
- DV = road accidents (continuous from 0 to Inf.)
- IV1 = alcohol consumption (continuous from 0L to Inf.L)
- IV2 = driving experience (categorical low, high)

```{r eval=TRUE, fig.align="left"}
DiagrammeR::grViz("
  digraph {
    graph [rankdir = LR]
  
    node []
    'alcohol consumption'; 'road accidents'; 'driving experience'
    node [shape = point, width = 0, height = 0]
    ''
    
    'driving experience' -> ''
    'alcohol consumption' -> '' [arrowhead = none]
    ''-> 'road accidents'
    
    subgraph {
      rank = same; 'driving experience' ; '';
    }
  }", height = 200)
```

--

Hypothesis:

- The effect of alcohol consumption on road accidents is lower for experienced drivers than for inexperienced drivers

---

# Mediation Effect Hypothesis

```{r eval=TRUE}
DiagrammeR::grViz("
  digraph {
    graph [rankdir = LR]
  
    node [shape = circle]
    Z; X; Y
    
    X -> {Y Z}
    Z -> Y

  }", height = 200)
```

can be read as: 
- "the main effect of X on Y is explained by Z"

Warning, it involves 3 requirements:
- "X have a **main** effect on Y"
- "X have a **main** effect on Z"
- "the **main** effect of X on Y **disappears** when Z is taken into account"

Replace with yours:

The effect of {**IV1**} on {**DV**} is mediated by {**IV2/Med**}

---

# Mediation Effect Hypothesis Example

Variables:
- DV = happiness (continuous from 0 to 7)
- IV1 = math exam results (continuous from 0 to 100)
- IV2 = self-esteem (continuous from 0 to 7)

```{r eval=TRUE, fig.align="left"}
DiagrammeR::grViz("
  digraph {
    graph [rankdir = LR]
  
    node []
    'self-esteem'; 'math exam results'; happiness
    
    'math exam results' -> {happiness 'self-esteem'}
    'self-esteem' -> happiness

  }", height = 200)
```

--

Hypothesis:
- the effect of math exam results on happiness is mediated by self-esteem

---

# Example of Hypotheses in Research Papers

```{r out.width = "50%"}
knitr::include_graphics("img/ex1_title.png")
```

```{r out.width = "50%"}
knitr::include_graphics("img/ex1_hyp.png")
```

---

# Example of Hypotheses in Research Papers

```{r out.width = "50%"}
knitr::include_graphics("img/ex2_title.png")
```

```{r out.width = "50%"}
knitr::include_graphics("img/ex2_hyp1.png")
```

```{r out.width = "50%"}
knitr::include_graphics("img/ex2_hyp2.png")
```

---

# Find DVs and IVs in these Hypotheses

- Overweight adults who value longevity are more likely than other overweight adults to lose their excess weight

- Larger animals of the same species expend more energy than smaller animals of the same type.

- Rainbow trout suffer more lice when water levels are low than other trout.

- Professors who use a student-centered teaching method will have a greater positive rapport with their graduate students than professors who use a teacher-centered teaching method.

---

# Make your own Hypothesis

|DV|IV1|IV2|
|--|---|---|
|Work motivation|Gender(Female/Male)|/|
|Work motivation|Gender(Female/Male)|Origin(French/Irish)|
|Work motivation|Gender(Female/Male)|Origin(French/Irish/Italians)|
|Job Satisfaction|Stress(from 0 to 10)|/|
|Job Satisfaction|Stress(from 0 to 10)|Origin(French/Irish)|
|Job Satisfaction|Stress(from 0 to 10)|Age(Millennials/Baby boomers)|
|Job Satisfaction|Stress(from 0 to 10)|Age(in year)|

---

# A Hypothesis Checklist

- Does your hypothesis focus on something that you can actually test?
- Does your hypothesis include both an independent and dependent variable?
- Can you manipulate the variables?

---
class: title-slide, middle

## Exercise

In the research paper you have selected, identify or formulate the tested hypotheses (10min)

---
class: inverse, mline, center, middle

# 3. Model

---

# Structure of Models

Models are an overview of the predicted relationship between variables stated in hypothese


In a model, **an arrow is an effect**

Example:

```{r eval=TRUE}
DiagrammeR::grViz("
digraph rmarkdown {
  graph [rankdir = LR]
  
  node [shape = oval]
  'Intention to Use'
  
  node [shape = box]
  'Actual Use'
        
  'Intention to Use' -> 'Actual Use'
}
", height = 200)
```

can be read as "Intention to Use has an effect on Actual Use".

---

# Structure of Models

Models are graphical representations of theories that highlight hypotheses:
- all the relations correspond to an hypothesis to be tested
- all the tested hypotheses have to be in the model

Distinguish square and circles
- **squares** are actual **measures/items**
- **circles** are **latent variables** related to measures/items

Example:
- *Actual Use* is directly measured (time spend in min) so it's a square.
- *Perceived Usefulness* is a latent variable with several questions so it's a circle.

Items used for latent variables can be omitted in a model, variables are the most important.

We can distinguish 2 types of relationship in a model:
- Main effect relationship
- Interaction effect relationship

---

# Main Effect Relationship

.pull-left[
The relation between one variable and another:

```{r eval=TRUE, fig.align="left"}
DiagrammeR::grViz("
  digraph {
    graph [rankdir = LR]
    node [shape = circle]
    
    X -> Y
  }", height = 200, width = 200)
```

can be read as:
- "X has a **main** effect on Y"
]
.pull-right[
A model can have multiple main effects: 

```{r eval=TRUE}
DiagrammeR::grViz("
  digraph {
    graph [rankdir = LR]
    node [shape = circle]
    
    X -> Y
    Z -> Y
  }", height = 200, width = 200)
```

can be read as: 
- "X has a **main** effect on Y"
- "Z has a **main** effect on Y"
]

---

# Interaction Effect Relationship

The relation between two predictor variables and another outcome variable. An interaction means that **the effect of X on Y will be different according the possibilities of Z** (also called Moderation).

.pull-left[
classic representation:
```{r eval=TRUE}
DiagrammeR::grViz("
  digraph {
    graph [rankdir = LR]
  
    node [shape = circle]
    X; Y; Z
    node [shape = point, width = 0, height = 0]
    ''
    
    Z -> ''
    X -> '' [arrowhead = none]
    ''-> Y
    
    subgraph {
      rank = same; Z; '';
    }
  }", height = 200, width = 300)
```
]

.pull-right[
is the same as:
```{r eval=TRUE}
DiagrammeR::grViz("
  digraph {
    graph [rankdir = LR]
    node [shape = circle]
    
    X -> Y
    Z -> Y
    'X*Z' -> Y
  }", height = 200, width = 200)
```
]

The arrow crossing the main effect arrow can be read as :
- "X have a **main** effect on Y"
- "Z have a **main** effect on Y"
- "X and Z have an **interaction** effect on Y"

---

# Model's Constraints

1. Every model is made of one or multiple main effect and/or interaction effect relationships

2. Control variables are not included in models

---

# Types of Model

## Simple Model

- One or more predictors
- Only one outcome
- Made of main or/and interaction effects

## Mediation Model (simple or moderated)

- At least 2 predictors (one call Mediator)
- Only one outcome
- Made of main effects only for simple mediation / main and interaction effects for moderated mediation

## Structural Equation Model (SEM)

- At least 2 predictors (usually latent variables)
- One or more outcome
- Made of main or/and interaction effects

---

# Simple Model

Simple Models are the most statistically powerful, easy to test and reliable models. Always prefer a simple model compared to a more complicated solution.

Warning, including interaction effect requires a significantly higher sample size (see calculation of power/effect size).

Example:

```{r eval=TRUE}
DiagrammeR::grViz("
  digraph {
    graph [rankdir = LR]
  
    node [shape = circle]
    'Salary'; 'Job Satisfaction'; 'Gender'; 'Holidays'
    node [shape = point, width = 0, height = 0]
    ''
    
    'Holidays' -> 'Job Satisfaction'
    'Gender' -> ''
    'Salary' -> '' [arrowhead = none]
    '' -> 'Job Satisfaction'
    
    subgraph {
      rank = same; 'Gender'; '';
    }
    subgraph {
      rank = same; 'Holidays'; 'Salary';
    }
  }", height = 200, width = 300)
```

---

# Mediation Models

A Mediation model is a complex path analysis between 3 variables, where one of them explains the relationship between the other two. It is usually used to identify cognitive process in psychology.

Example:

```{r eval=TRUE, fig.align="left"}
DiagrammeR::grViz("
  digraph {
    graph [rankdir = LR]
  
    node []
    'self-esteem'; 'math exam results'; happiness
    
    'math exam results' -> {happiness 'self-esteem'}
    'self-esteem' -> happiness

  }", height = 200)
```

---

# Structural Equation Model

A Structural Equation Model (SEM) is a complex path analysis between multiple variables including multiple Outcomes and using factor analysis for latent variable estimation.

```{r eval=TRUE}
DiagrammeR::grViz("
digraph rmarkdown {
  graph [rankdir = LR]
  
  node [shape = oval]
  'Perceived Ease-of-use'; 'Perceived Usefulness'; 'Intention to Use'; 'Actual Use'
  
  node [shape = box]
  PU1; PU2; PU3; PU4; PU5; PEOU1; PEOU2; PEOU3; PEOU4; BI1; BI2; AU
  
  {PU1 PU2 PU3 PU4 PU5} -> 'Perceived Usefulness' [arrowhead = none]
  {PEOU1 PEOU2 PEOU3 PEOU4} -> 'Perceived Ease-of-use' [arrowhead = none]
  {BI1 BI2} -> 'Intention to Use' [arrowhead = none]
  {AU} -> 'Actual Use' [arrowhead = none]
  
  'Perceived Usefulness' -> 'Intention to Use'
  'Perceived Ease-of-use' -> {'Perceived Usefulness' 'Intention to Use'}
  'Intention to Use' -> 'Actual Use'
  
  subgraph {
      rank = same; 'Perceived Usefulness'; 'Perceived Ease-of-use';
  }
  
  subgraph {
      rank = same; PU1; PU2; PU3; PU4; PU5; PEOU1; PEOU2; PEOU3; PEOU4; BI1; BI2;
  }

}
", height = 400)
```

---

# A Good Model

- Comprehensiveness: Explains a wide range of phenomena
- Internal Consistency: Propositions and assumptions are consistent and fit together in a coherent manner
- Parsimony: Contains only those concepts and assumptions essential for the explanation of a phenomenon
- Testability: Concepts and relational statements are precise.
- Empirical Validity: Holds up when tested in the real world.

Example: 

```{r eval=TRUE}
DiagrammeR::grViz("
digraph rmarkdown {
  graph [rankdir = LR]
  
  node [shape = oval]
  'Perceived Ease-of-use'; 'Perceived Usefulness'; 'Intention to Use'
  
  node [shape = box]
  'Actual Use'
  
  'Perceived Usefulness' -> 'Intention to Use'
  'Perceived Ease-of-use' -> {'Perceived Usefulness' 'Intention to Use'}
  'Intention to Use' -> 'Actual Use'
  
  subgraph {
      rank = same; 'Perceived Usefulness'; 'Perceived Ease-of-use';
  }
}
", height = 100)
```

---

# A bad Theory/Model

- too complicated
- does not explain many things
- cannot be tested

Is it bad?

![](https://d3i71xaburhd42.cloudfront.net/2a3e4a3024bfc4df27db07a1d48f77a6f371b0c3/8-Figure1-1.png)

---
class: title-slide, middle

## Exercise

In the research paper you have selected, draw the model(s) tested (10min)

---
class: inverse, mline, center, middle

# 4. Equation

---

# What is a Correlation?

A correlation indicate the strength and direction of a relationship and uses the letter $\beta$

It has a value between 1 and -1
- 1 indicates a strong and positive relationship
- -1 indicates a strong and negative relationship
- 0 indicates no relationship

---

# What is a Correlation?

```{r out.width = "70%"}
knitr::include_graphics("img/correlation.png")
```

---

# Evaluation of the Significance

Once all the hypotheses are formulated, it is time to test all of them in one unique model. In this model, a value called $\beta$ which is usually the coefficient of correlation is associated to each predictor from the hypotheses. 

Testing for the significance of the effect means evaluating if this $\beta$ value is significantly different, higher or lower than 0 (no link between variables):

- $H_a: \beta \neq 0$ means our hypothesis doesn't precise the direction of the change, just that there is a change


- $H_a: \beta > 0$ means our hypothesis indicates that the relationship increases or a group is higher than another group

- $H_a: \beta < 0$ means our hypothesis indicates that the relationship decreases or a group is lower than another group

- The Null hypothesis will always be $H_0: \beta = 0$

---

# A Basic Equation

The basic structure of a statistical model is:

$$data = model + error$$

where the $model$ is a series of predicted relationships/hypotheses.

This expresses the idea that the data can be described by a statistical model, which expresses what we expect to occur in the data, along with the difference between the model and the data, which we refer to as the error.

---

# A Basic Equation

Let's imagine the perfect scenario: **your predictor variable X explains perfectly the outcome variable Y**.

The corresponding equation is: $Y = X$

.pull-left[
```{r, eval=TRUE}
knitr::kable(data.frame(X = 1:10, Y = 1:10), format = "html")
```
]
.pull-right[
```{r eval=TRUE, fig.height=5}
data.frame(X = 0:10, Y = 0:10) %>% 
  ggplot(aes(X, Y)) +
  geom_point(color = "black", size = 5) +
  geom_smooth(method = "lm") +
  scale_x_continuous(limits = c(0,10)) +
  scale_y_continuous(limits = c(0,10)) +
  theme_bw()
```
]

---

# A Basic Equation

In the equation $Y = X$, three coefficients are hidden because they are unused:
- the intercept coefficient $\beta_{0}$ corresponds to the value of Y when X = 0
    - which is O in our case
- the slope coefficient $\beta_{1}$ corresponds to how much Y increase when X increase of 1
    - which is 1 in our case
- the error coefficient $\epsilon$ corresponds to how far from the prediction line the values of Y are
    - which is 0 in our case

So in general, the relation between a predictor and an outcome can be written as:
$$Y = \beta_{0} + \beta_{1} . X + \epsilon$$

which is in our case:

$$Y = 0 + 1 * X + 0$$

---

# A Basic Equation

The equation $Y = \beta_{0} + \beta_{1}.X + \epsilon$ is the same as the good old $y = ax + b$ (here ordered as $y = b + ax$) where $\beta_{0}$ is $b$ and $\beta_{1}$ is $a$.

It is very important to know that under **EVERY** statistical test, a similar equation is used (t-test, ANOVA, Chi-square are all linear regressions).

```{r fig.width=5.5, fig.height=5.5}
plot0 <- data.frame(X = 0:9, Y = 0:9) %>%
  ggplot(aes(X, Y)) +
  geom_point(color = "black", size = 5) +
  geom_smooth(method = "lm") +
  geom_hline(yintercept = 0, color = 'black', size = 0.5, linetype = 'dotted') +
  annotate("text", x = 5, y = 0.2, label = "Intercept \u03b2\u2080") +
  annotate('segment', x = 5, xend = 6, y = 5, yend = 5, color = 'red') +
  annotate('segment', x = 6, xend = 6, y = 5, yend = 6, color = 'red') +
  annotate("text", x = 7.5, y = 5.5, label = "Slope \u03b2\u2081") +
  scale_x_continuous(breaks = seq(0:9)) +
  scale_y_continuous(breaks = seq(0:9)) +
  theme_bw()

plotly::ggplotly(plot0)
```

---

# Equations and Variable Categories

For this first lecture, all examples are using **continuous Outcome/Dependant Variables** and **continuous Predictor/Independent Variables**:

- Categorical Outcome/Dependant Variables involves a logistic regression NOT a linear regression. Even if the equation will stay the same, the distribution of the residual will change. For the moment only focus on **continuous Outcome/Dependant Variables**

- **Categorical** Predictor/Independent Variables can be used in the exact same way as **continuous** Predictor/Independent Variables for main and interaction effects. We will see why in a future lecture.

Examples:

$$MathResults = \beta_{0} + \beta_{1}.IQ + \epsilon$$

$$MathResults = \beta_{0} + \beta_{1}.IQ + \beta_{2}.age + \beta_{3}.IQ*age + \epsilon$$

$$MathResults = \beta_{0} + \beta_{1}.IQ + \beta_{2}.gender + \epsilon$$

$$MathResults = \beta_{0} + \beta_{1}.IQ + \beta_{2}.gender + \beta_{3}.IQ*gender + \epsilon$$

---

# Relevance of the Intercept

To test hypotheses only the \beta values associated to the Predictor /Independent Variables are important.

The intercept is always included in an equation but its result is useless for hypothesis testing.

Let's see why the intercept is always included but its results discarded.

Imagine we want to test the relationship between GDP per Capita and Life Expectancy of countries in the world. Let's compare a model without and a model with intercept:

- Without intercept: $Life\,Expectancy = \beta_{1}.GDP\,per\,Capita + \epsilon$

- With intercept: $Life\,Expectancy = \beta_{0} + \beta_{1}.GDP\,per\,Capita + \epsilon$

---

# Relevance of the Intercept

```{r}
p1 <- gapminder %>% 
  filter(year == 2007) %>% 
  ggplot(aes(x = gdpPercap, y = lifeExp)) +
  geom_point() +
  scale_y_continuous(limits = c(0, 90)) +
  labs(
    title = "A: Original Data",
    x = "GDP per Capita ($)",
    y = "Life Expectancy"
  )

p2 <- gapminder %>% 
  filter(year == 2007) %>% 
  ggplot(aes(x = gdpPercap, y = lifeExp)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE, fullrange = TRUE, formula = "y ~ x + 0 ") +
  scale_y_continuous(limits = c(0, 90)) +
  labs(
    title = "B: Model without intercept",
    x = "GDP per Capita ($)",
    y = "Life Expectancy"
  )

p3 <- gapminder %>% 
  filter(year == 2007) %>% 
  ggplot(aes(x = gdpPercap, y = lifeExp)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE, fullrange = TRUE, formula = "y ~ x") +
  scale_y_continuous(limits = c(0, 90)) +
  labs(
    title = "C: Model with intercept",
    x = "GDP per Capita ($)",
    y = "Life Expectancy"
  )

p1 / (p2 + p3)
```

If the intercept is not included, the intercept is zero and can lead to estimation errors

---

# Basic Example

.pull-left[
```{r, eval=TRUE}
knitr::kable(data.frame(
  participant = c("ppt1", "ppt2", "ppt3", "ppt4", "ppt5", "ppt6"), 
  IQ = c(120, 103, 96, 87, 114, 95),
  math_results = c(89, 64, 71, 77, 78, 69)
  ), 
  format = "html")
```
]
.pull-right[
```{r eval=TRUE, fig.height=5}
data.frame(
  participant = c("ppt1", "ppt2", "ppt3", "ppt4", "ppt5", "ppt6"), 
  IQ = c(120, 103, 96, 87, 114, 95),
  math_results = c(89, 64, 71, 77, 78, 69)
  ) %>% 
  ggplot(aes(x = IQ, y = math_results, label = participant)) +
  geom_point(color = "black", size = 5) +
  #geom_smooth(method = "lm") +
  geom_text_repel(point.padding = 0.5, size = 14) +
  theme_bw() +
  theme(
    text = element_text(size = 14)
  )
```
]

---

# Basic Example

.pull-left[
Variables:
- DV = math results (from 0 to 100)
- IV = IQ (from 0 to Inf.)
]
.pull-right[
```{r eval=TRUE, fig.align="center"}
DiagrammeR::grViz("
  digraph {
    graph [rankdir = LR]
    node [shape = circle]
    
    IQ -> math_results [label= Î²1]
  }", height = 200, width = 200)
```
]

Hypothesis (one-tailed):
- $H_a$: When IQ increases, math results increases as well 

*if the line increases then that means $\beta_1$ > 0*

- $H_0$: When IQ increases, math results stay the same

*if the line stay the same then that means $\beta_1$ = 0*

Equation:

$$MathResults = \beta_{0} + \beta_{1}.IQ + \epsilon$$

---

# Example with Interaction

.pull-left[
```{r, eval=TRUE}
df4 <- data.frame(
  participant = c("ppt1", "ppt2", "ppt3", "ppt4", "ppt5", "ppt6"), 
  IQ = c(120, 103, 96, 87, 114, 95),
  age = c(20, 30, 40, 50, 60, 70),
  math_results = c(89, 64, 71, 77, 52, 69)
)

knitr::kable(df4, format = "html")
```
]
.pull-right[
```{r eval=TRUE, fig.height=5}
df4 %>% 
  ggplot(aes(x = IQ, y = math_results)) +
  geom_point(size = 5, aes(color = age)) +
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw() +
  theme(
    text = element_text(size = 14)
  )
```
]

---

# Example with Interaction

.pull-left[
```{r eval=TRUE}
DiagrammeR::grViz("
  digraph {
    graph [rankdir = LR]
  
    node [shape = circle]
    IQ; math_results; age
    node [shape = point, width = 0, height = 0]
    ''
    
    age -> ''
    IQ -> '' [arrowhead = none]
    ''-> math_results
    
    subgraph {
      rank = same; age; '';
    }
  }", height = 300, width = 400)
```
]

.pull-right[
```{r eval=TRUE}
DiagrammeR::grViz("
  digraph {
    graph [rankdir = LR]
  
    node [shape = circle]
    IQ; math_results;'IQ*age'; age

    age -> math_results [label= Î²2]
    IQ -> math_results [label= Î²1]
    'IQ*age' -> math_results [label= Î²3]
    
  }", height = 300, width = 300)
```
]

---

# Example with Interaction

Hypothesis (one-tailed): 
- $H_{a_{1}}$: When IQ increases, math results increases as well
- $H_{0_{1}}$: When IQ increases, math results stay the same

- $H_{a_{2}}$: When age increases, math results increases as well
- $H_{0_{2}}$: When age increases, math results stay the same

- $H_{a_{3}}$: the effect of age on math results increase when IQ increases
- $H_{0_{3}}$: the effect of age on math results stay the same when IQ increases

Equations:

$$MathResults = \beta_{0} + \beta_{1}.IQ + \beta_{2}.age + \beta_{3}.interaction + \epsilon$$

which equals to:

$$MathResults = \beta_{0} + \beta_{1}.IQ + \beta_{2}.age + \beta_{3}.IQ*age + \epsilon$$

---

# Mediation Effect

The mediation model is a path analysis which involves 3 different linear models.

Let's take the example in https://data.library.virginia.edu/introduction-to-mediation-analysis/

Data analysis is also presented here: https://jamovi-amm.github.io/glm_example1.html

Data used for this example can be downloaded here: https://jamovi-amm.github.io/glm_example1.html
- X = grades
- Y = happiness
- M = self-esteem

---

# Mediation Effect

Imagine that previous studies have suggested that higher grades predict higher happiness: X (grades) â Y (happiness). This is called **Direct Effect**.

```{r eval=TRUE, out.width = '70%'}
knitr::include_graphics("https://data.library.virginia.edu/files/mediation_ex1.png")
```

However, grades are not the real reason that happiness increases. Let's hypothesize that good grades boost oneâs self-esteem and then high self-esteem boosts oneâs happiness: X (grades) â M (self-esteem) â Y (happiness). This is called **Indirect Effect**.

```{r eval=TRUE, out.width = '70%'}
knitr::include_graphics("https://data.library.virginia.edu/files/mediation_ex2.png")
```

Self-esteem is a mediator that explains the underlying mechanism of the relationship between grades (IV) and happiness (DV).

---

# How to Analyse Mediation Effects?

A mediation analysis is comprised of three sets of regression: X â Y, X â M, and X + M â Y. They are just three regression analyses!

## Step 1

```{r eval=TRUE, out.width = '70%'}
knitr::include_graphics("https://data.library.virginia.edu/files/mediation_step1.png")
```

$$Y = \beta_{0} + \beta_{1}.X + \epsilon$$

Is $\beta_1$ significant? We want X to affect Y (Direct Effect). If there is no relationship between X and Y, there is nothing to mediate.

---

# How to Analyse Mediation Effects?

## Step 2

```{r eval=TRUE, out.width = '70%'}
knitr::include_graphics("https://data.library.virginia.edu/files/mediation_step2.png")
```

$$M = \beta_{0} + \beta_{2}.X + \epsilon$$

Is $\beta_2$ significant? We want X to affect M. If X and M have no relationship, M is just a third variable that may or may not be associated with Y. A mediation makes sense only if X affects M.

---

# How to Analyse Mediation Effects?

## Step 3

```{r eval=TRUE, out.width = '70%'}
knitr::include_graphics("https://data.library.virginia.edu/files/mediation_step3.png")
```

$$Y = \beta_{0} + \beta_{4}.X + \beta_{3}.M + \epsilon$$

Is $\beta_4$ non-significant or smaller than before? We want M to affect Y, but X to no longer affect Y (or X to still affect Y but in a smaller magnitude). If a mediation effect exists, the effect of X on Y will disappear (or at least weaken) when M is included in the regression. The effect of X on Y goes through M.

If the effect of X on Y completely disappears, M fully mediates between X and Y (full mediation). If the effect of X on Y still exists, but in a smaller magnitude, M partially mediates between X and Y (partial mediation).

---

# How to Analyse SEM?

In SEM, there are as many equation as there are Outcomes/Dependent Variables.

For example, in the following model: 

```{r eval=TRUE}
DiagrammeR::grViz("
digraph rmarkdown {
  graph [rankdir = LR]
  
  node [shape = oval]
  'Perceived Ease-of-use'; 'Perceived Usefulness'; 'Intention to Use'
  
  node [shape = box]
  'Actual Use'
  
  'Perceived Usefulness' -> 'Intention to Use'
  'Perceived Ease-of-use' -> {'Perceived Usefulness' 'Intention to Use'}
  'Intention to Use' -> 'Actual Use'
  
  subgraph {
      rank = same; 'Perceived Usefulness'; 'Perceived Ease-of-use';
  }
}
", height = 100)
```

Three equations are tested
$$PU = \beta_{0} + \beta_{1}.PEOU + \epsilon$$

$$IU = \beta_{0} + \beta_{2}.PU + \beta_{3}.PEOU + \epsilon$$

$$AU = \beta_{0} + \beta_{4}.IU + \epsilon$$

---
class: title-slide, middle

## Exercise

In the research paper you have selected, write the equation corresponding to the model(s) (10min)

---

class: inverse, mline, center, middle

# Conclusion

---

# Understand your Analyses

```{r out.width="50%"}
tweetrmd::tweet_screenshot(
  tweetrmd::tweet_url("dan_a_chapman", "1326647958314622977"),
  maxwidth = 300,
  hide_media = FALSE,
  theme = "dark"
  )
```

---

# Understand your Analyses

```{r out.width="50%"}
tweetrmd::tweet_screenshot(
  tweetrmd::tweet_url("JeffRouder", "1326938465938726915"),
  maxwidth = 300,
  hide_media = FALSE,
  theme = "dark"
  )
```

---

# The General Linear Model

```{r out.width="50%"}
tweetrmd::tweet_screenshot(
  tweetrmd::tweet_url("kylehamilton", "1349225426669817856"),
  maxwidth = 300,
  hide_media = FALSE,
  theme = "dark"
  )
```

---
class: title-slide, middle

## Exercise

Have a look at David's paper (uploaded on loop) and identify the potential problems with the variables/model/hypotheses

---
class: inverse, mline, left, middle

<img class="circle" src="https://github.com/damien-dupre.png" width="250px"/>

# Thanks for your attention and don't hesitate if you have any question!

[`r fa(name = "twitter")` @damien_dupre](http://twitter.com/damien_dupre)  
[`r fa(name = "github")` @damien-dupre](http://github.com/damien-dupre)  
[`r fa(name = "link")` damien-datasci-blog.netlify.app](https://damien-datasci-blog.netlify.app)  
[`r fa(name = "paper-plane")` damien.dupre@dcu.ie](mailto:damien.dupre@dcu.ie)
